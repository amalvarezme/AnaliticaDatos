{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPleyz6xK4S1a11j18FkPT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amalvarezme/AnaliticaDatos/blob/master/FaceRecognition/FaceTagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python face_recognition -q"
      ],
      "metadata": {
        "id": "b2fqDtbg10l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/amalvarezme/FaceRecognition.git"
      ],
      "metadata": {
        "id": "5nxU2mCJFRjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSjAuckP1wSr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Load the labeled face image and encode it\n",
        "labeled_image_path = 'FaceRecognition/gcpds.jpeg'  # Replace with the path to your labeled face image\n",
        "labeled_image = face_recognition.load_image_file(labeled_image_path)\n",
        "labeled_image = cv2.resize(labeled_image, (2048,1152))\n",
        "\n",
        "plt.imshow(labeled_image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_locations = face_recognition.face_locations(labeled_image, number_of_times_to_upsample=1)\n",
        "print(f'face detected: {len(face_locations)}')"
      ],
      "metadata": {
        "id": "8BRNM1PKHWmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def loc_faces(image_,face_locations,linew_=2,font_s=2,save_=True,output_dir=None,h_=80,w_=80):\n",
        "  # Loop over each face found in the image\n",
        "  i = 0\n",
        "  Nf = len(face_locations)\n",
        "  faces = np.zeros((Nf,h_,w_,image_.shape[-1]))\n",
        "\n",
        "  if save_:\n",
        "    for (top, right, bottom, left) in face_locations:\n",
        "        print(f'face {i+1}/{Nf}')\n",
        "\n",
        "        # Extract the face from the frame\n",
        "        face_image = cv2.resize(cv2.cvtColor(image_[top:bottom, left:right], cv2.COLOR_RGB2BGR),(h_, w_))\n",
        "\n",
        "        # Save the face image as a file\n",
        "        face_filename = os.path.join(output_dir, f\"face_{i+1}.jpg\")\n",
        "        cv2.imwrite(face_filename, face_image)\n",
        "        faces[i] = face_image\n",
        "        i+=1\n",
        "  i=0\n",
        "  for (top, right, bottom, left) in face_locations:\n",
        "    print(f'face {i+1}/{Nf}')\n",
        "    # Draw a rectangle around the matching face\n",
        "    cv2.rectangle(image_, (left, top), (right, bottom), (0, 255, 0), linew_)\n",
        "    #cv2.putText(image_, 'f'+str(i+1), (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_s, (0, 255, 0), linew_)\n",
        "    i+=1\n",
        "\n",
        "  return image_,faces"
      ],
      "metadata": {
        "id": "jgKDvqd0HmY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to save detected faces\n",
        "%matplotlib inline\n",
        "output_dir = \"gcpds_detected_faces\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "\n",
        "image_ = labeled_image.copy()\n",
        "\n",
        "image_,faces = loc_faces(image_,face_locations,\n",
        "                         save_= True,output_dir=output_dir)\n",
        "plt.imshow(image_)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TWtAv2PTHgO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipympl -q\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n"
      ],
      "metadata": {
        "id": "Z8dAgtYl2HUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#bounding box faces not detected\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "# Global variable to store the selected points\n",
        "ref_points = []\n",
        "ref_points_ = []\n",
        "\n",
        "# Mouse event handler function\n",
        "def onclick(event):\n",
        "    global ref_points, ref_points_\n",
        "\n",
        "    # If you click inside the axes\n",
        "    if event.xdata and event.ydata:\n",
        "        # Store the click position as (x, y)\n",
        "        ref_points_.append((int(event.xdata), int(event.ydata)))\n",
        "        print(ref_points_)\n",
        "\n",
        "        # Once two points are clicked, draw the rectangle\n",
        "        if len(ref_points_) == 2:\n",
        "           ref_points.append(ref_points_)\n",
        "           ref_points_ = []\n",
        "           draw_rectangle(ref_points[-1])\n",
        "\n",
        "\n",
        "# Function to draw the bounding box after two clicks\n",
        "def draw_rectangle(points):\n",
        "\n",
        "\n",
        "    (x1, y1), (x2, y2) = points\n",
        "\n",
        "    width = x2 - x1\n",
        "    height = y2 - y1\n",
        "\n",
        "    # Draw the rectangle on the same figure without resetting\n",
        "    rect = Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
        "\n",
        "\n",
        "    # Add the rectangle to the plot and refresh the figure\n",
        "    ax.add_patch(rect)\n",
        "    fig.canvas.draw()\n",
        "\n"
      ],
      "metadata": {
        "id": "bFFpAMqMzU6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.imshow(image_)\n",
        "plt.show()\n",
        "\n",
        "%matplotlib ipympl\n",
        "\n",
        "# Convert the image from BGR to RGB for displaying with matplotlib\n",
        "image_rgb = labeled_image.copy()# cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image using matplotlib\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(image_rgb)\n",
        "\n",
        "# Connect the click event to the figure\n",
        "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ihtxh5HN0E1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_points"
      ],
      "metadata": {
        "id": "xSOtBCeg0k2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_locations_ = face_locations\n"
      ],
      "metadata": {
        "id": "kkjSUUzkGSBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "any(ref_points)"
      ],
      "metadata": {
        "id": "hpjRmpzkLtzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if any(ref_points):\n",
        "  for ref_add in ref_points:\n",
        "    (left, top), (right, bottom) = ref_add\n",
        "    print(top,bottom,left,right)\n",
        "    face_locations_.append((top,right,bottom,left))"
      ],
      "metadata": {
        "id": "GYyXZ6J-FWxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "image2_ = labeled_image.copy()\n",
        "image2_,faces = loc_faces(image2_,face_locations_,\n",
        "                         save_= True,output_dir=output_dir)\n",
        "plt.imshow(image2_)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Er6KyCd-IBi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_encoding_ = np.array(face_recognition.face_encodings(labeled_image, known_face_locations=face_locations_))  # Get face encoding for the labeled face\n"
      ],
      "metadata": {
        "id": "W20xDuml4Nm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pcolormesh(face_encoding_)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y4Av5r3lTQ4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install umap-learn -q #librer√≠a umap"
      ],
      "metadata": {
        "id": "vvNy_dOvT_uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "red = umap.UMAP(n_components=2,n_neighbors=3, min_dist=0.2)\n",
        "Z = red.fit_transform(face_encoding_)"
      ],
      "metadata": {
        "id": "oEgiKovQUAxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox #plot mnist 2D\n",
        "def plot_mnist_2d(Z,y,images,img_w=28,img_h=28,zoom=0.5,cmap='jet'):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    for i in range(Z.shape[0]):\n",
        "        #print('img',i+1,'/',Z.shape[0])\n",
        "        image =  cv2.resize(images[i],(img_w,img_h))\n",
        "        im = OffsetImage(image[:,:,[2,1,0]], zoom=zoom,cmap=cmap)\n",
        "        ab = AnnotationBbox(im, (Z[i,0], Z[i,1]), xycoords='data', frameon=False)\n",
        "        ax.add_artist(ab)\n",
        "        ax.update_datalim([(Z[i,0], Z[i,1])])\n",
        "        ax.autoscale()"
      ],
      "metadata": {
        "id": "x209tR-YUpXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_mnist_2d(Z,np.ones((Z.shape[0])),faces/255.)"
      ],
      "metadata": {
        "id": "l3WeRkgpVNte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openpyxl\n",
        "from openpyxl.drawing.image import Image as ExcelImage\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "\n",
        "def excel_faces(dir_,faces):\n",
        "  # Create a new workbook and select the active worksheet\n",
        "  wb = openpyxl.Workbook()\n",
        "  ws = wb.active\n",
        "\n",
        "  # Loop over the images in the array and insert them into the Excel file\n",
        "  for row in range(faces.shape[0]):\n",
        "      # Convert the NumPy image to a PIL image\n",
        "      img_array = np.uint8(faces[row])\n",
        "      img_pil = Image.fromarray(img_array[:,:,[2,1,0]])\n",
        "\n",
        "      # Save the PIL image into a bytes buffer\n",
        "      img_buffer = io.BytesIO()\n",
        "      img_pil.save(img_buffer, format='PNG')\n",
        "      img_buffer.seek(0)\n",
        "\n",
        "      # Convert the bytes buffer into an image that openpyxl can use\n",
        "      img_excel = ExcelImage(img_buffer)\n",
        "\n",
        "      # Resize the image to 80x80\n",
        "      img_excel.width, img_excel.height = 80, 80\n",
        "\n",
        "      # Insert the image into the worksheet, in column 'A'\n",
        "      cell = f'A{row+2}'\n",
        "      ws.add_image(img_excel, cell)\n",
        "\n",
        "      # Insert the face ID in column 'B'\n",
        "      cell_face_id = f'B{row+2}'\n",
        "      ws[cell_face_id] = row+2\n",
        "\n",
        "      # Insert the name in column 'C'\n",
        "      cell_name = f'C{row+2}'\n",
        "      plt.imshow(img_array[:,:,[2,1,0]])\n",
        "      plt.show()\n",
        "\n",
        "      name_ = input('name: ')\n",
        "      ws[cell_name] = name_\n",
        "\n",
        "\n",
        "      # Set the row height to 80\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ws.column_dimensions['A'].width = 12.0  # Adjusted to match 80px roughly for Excel\n",
        "  # Set the column width for 'B' and 'C' for face IDs and names\n",
        "  ws.column_dimensions['B'].width = 15  # Adjust this as necessary\n",
        "  ws.column_dimensions['C'].width = 20  # Adjust this as necessary\n",
        "  for row in range(faces.shape[0]):\n",
        "    ws.row_dimensions[row+2].height = 60\n",
        "\n",
        "\n",
        "\n",
        "  # Save the workbook as an Excel file\n",
        "  wb.save('images_from_numpy.xlsx')\n",
        "\n",
        "  print(\"Excel file with images saved!\")\n",
        "  return\n"
      ],
      "metadata": {
        "id": "_71ZwGUsX2ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "excel_faces(dir_=output_dir,faces=faces)"
      ],
      "metadata": {
        "id": "ESkinDZoZy2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create dictionary\n",
        "\n",
        "dic_ = {'tagged': faces,\n",
        "        'encodings': face_encoding_,\n",
        "\n",
        "         }"
      ],
      "metadata": {
        "id": "WvdjlTcsNh3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image where you want to find and tag the face\n",
        "#image_to_tag_path = 'Salo_predict.JPG'  # Replace with the path to the image where you want to find the face\n",
        "#image_to_tag = face_recognition.load_image_file(image_to_tag_path)\n",
        "\n",
        "\n",
        "\n",
        "# Detect faces in the new image\n",
        "#face_locations = face_recognition.face_locations(image_to_tag)\n",
        "#face_encodings = face_recognition.face_encodings(image_to_tag, face_locations)\n",
        "#linew_ = 5\n",
        "# Convert image to BGR format for OpenCV display (face_recognition uses RGB by default)\n",
        "#image_to_tag_bgr = cv2.cvtColor(image_to_tag, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Loop over each face found in the image\n",
        "#i = 0\n",
        "#for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "#    print('face :',i+1)\n",
        "#    i+=1\n",
        "    # Check if the detected face matches the labeled face\n",
        "#    matches = face_recognition.compare_faces([labeled_face_encoding], face_encoding)\n",
        "\n",
        "    # If a match is found, tag the face\n",
        " #   if matches[0].any():\n",
        "        # Draw a rectangle around the matching face\n",
        "  #      cv2.rectangle(image_to_tag, (left, top), (right, bottom), (0, 255, 0), linew_)\n",
        "   #     cv2.putText(image_to_tag, labeled_image_path[:-4], (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 4, (0, 255, 0), linew_)\n",
        "\n"
      ],
      "metadata": {
        "id": "u6PSGskO3vS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.imshow(labeled_image)\n",
        "#plt.show()\n",
        "\n",
        "# Display the result\n",
        "#plt.imshow(image_to_tag)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Optionally, save the output image\n",
        "#cv2.imwrite('tagged_image.jpg', image_to_tag_bgr)\n"
      ],
      "metadata": {
        "id": "bOk131Hv3zJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#face_locations"
      ],
      "metadata": {
        "id": "GsMixZwf2ra9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YA9SSYGA3Z1n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}